{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68fefa05-e185-4240-b559-f3a341e18906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c7d945-8832-4d65-acc7-f4d205a64645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>rus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293576</th>\n",
       "      <td>I saw your brother the other day.</td>\n",
       "      <td>Я тут как-то видел твоего брата.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316800</th>\n",
       "      <td>Your strategy seems to be working.</td>\n",
       "      <td>Похоже, твоя стратегия работает.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67229</th>\n",
       "      <td>Hatred is our enemy.</td>\n",
       "      <td>Ненависть — наш враг.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404616</th>\n",
       "      <td>Tom should have discussed the matter with me.</td>\n",
       "      <td>Тому надо было обсудить этот вопрос со мной.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208198</th>\n",
       "      <td>I told Tom not to come here.</td>\n",
       "      <td>Я сказала Тому не приходить сюда.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  eng  \\\n",
       "293576              I saw your brother the other day.   \n",
       "316800             Your strategy seems to be working.   \n",
       "67229                            Hatred is our enemy.   \n",
       "404616  Tom should have discussed the matter with me.   \n",
       "208198                   I told Tom not to come here.   \n",
       "\n",
       "                                                 rus  \n",
       "293576              Я тут как-то видел твоего брата.  \n",
       "316800              Похоже, твоя стратегия работает.  \n",
       "67229                          Ненависть — наш враг.  \n",
       "404616  Тому надо было обсудить этот вопрос со мной.  \n",
       "208198             Я сказала Тому не приходить сюда.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"rus.txt\"\n",
    "data = pd.read_table(data_path,  usecols=range(2), names=['eng', 'rus'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63e4187-285d-4adf-8cbd-45fdf664aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440219, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7525a165-50a8-4380-96d6-0ba8440bf50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 15000\n",
    "train_set = data.sample(samples)\n",
    "\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7112804-3dc4-401d-aea9-95595cf1cdcc",
   "metadata": {},
   "source": [
    "Make everything lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a810f24-2c15-42cb-9d86-0e1480217eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.eng = train_set.eng.apply(lambda x: x.lower())\n",
    "train_set.rus = train_set.rus.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f776c3-ecb9-4e42-bf8a-0f82db5fae39",
   "metadata": {},
   "source": [
    "Remove punctuation - https://stackoverflow.com/questions/33047818/remove-punctuation-for-each-row-in-a-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32278591-a4a2-433d-bb57-741ffdb1dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.eng = train_set.eng.apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "train_set.rus = train_set.rus.apply(lambda x:''.join([i for i in x if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3fc0d-5b84-49ee-88a6-b4462d0f5f2e",
   "metadata": {},
   "source": [
    "Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa6f8b0-f5e7-4734-97bd-58ce3791a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.eng = train_set.eng.apply(lambda x: x.strip())\n",
    "train_set.rus = train_set.rus.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba9e56-c6e8-424d-8f1d-ca6cbe3a89ed",
   "metadata": {},
   "source": [
    "Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc13883-18ad-4921-b3b6-7fbc1538ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "train_set.eng=train_set.eng.apply(lambda x: x.translate(remove_digits))\n",
    "train_set.rus=train_set.rus.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "eng_lengths = train_set.eng.str.split(' ')\n",
    "max_eng = eng_lengths.str.len().max()\n",
    "rus_lengths = train_set.rus.str.split(' ')\n",
    "max_rus = rus_lengths.str.len().max()\n",
    "MAX_L= max(max_rus,max_eng) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fcabcf9-9fb4-4356-a4fe-49270fdc4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = \"E_\"\n",
    "start_token = \"S_\"\n",
    "end_index = 0\n",
    "start_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a00517-3b5c-4234-866e-94263a7c0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self):\n",
    "        self.word2index = {end_token: end_index, start_token: start_index}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {end_index: end_token, start_index: start_token}\n",
    "        self.n_words = 2 #E_ and S_\n",
    "    \n",
    "    def addToVector(self, line):\n",
    "        for w in line.split(' '):\n",
    "            if w not in self.word2index:\n",
    "                self.word2index[w] = self.n_words\n",
    "                self.word2count[w] = 1\n",
    "                self.index2word[self.n_words] = w\n",
    "                self.n_words += 1\n",
    "            else:\n",
    "                self.word2count[w] += 1\n",
    "                \n",
    "    def vectorize_line(self, line):\n",
    "        return [self.word2index[w] for w in line.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7654b22-625d-4698-9a55-03f8e27b4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_vec = Vectorizer()\n",
    "eng_vec = Vectorizer()\n",
    "\n",
    "for rus,eng in zip(train_set.rus,train_set.eng):\n",
    "    rus_vec.addToVector(rus)\n",
    "    eng_vec.addToVector(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33140fb0-7fbf-4668-a0de-0958bf20e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4926\n"
     ]
    }
   ],
   "source": [
    "print(eng_vec.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58cf627a-af9a-409c-b621-7c583fcc3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.initial_hidden = torch.zeros(1,1,self.hidden_size,device=device)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).view(1, 1, -1) #fill\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda6037-1771-4199-87dd-d634c0fea8ed",
   "metadata": {},
   "source": [
    "Using GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f389e96-71d9-4c37-a7b8-3092ab78ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout=0.1, max_l=MAX_L):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "        self.max_l = max_l\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_l)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.initial_hidden=torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    def forward(self, input, hidden,enc_outs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 enc_outs.unsqueeze(0))\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00bac6-d5bd-417e-8d19-7297574121ba",
   "metadata": {},
   "source": [
    "Convert pair of sentences to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d35d83-d640-418f-b76d-cecf830d29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensors(pair):\n",
    "    eng_s=pair.iloc[0]['eng'] + ' ' + end_token\n",
    "    rus_s=pair.iloc[0]['rus'] + ' ' + end_token\n",
    "    input_t=torch.tensor(eng_vec.vectorize_line(eng_s), dtype=torch.long, device=device).view(-1, 1)\n",
    "    target_t=torch.tensor(rus_vec.vectorize_line(rus_s), dtype=torch.long, device=device).view(-1, 1)\n",
    "    return input_t,target_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168192e9-b89a-4b75-91ed-e5a45c3f152a",
   "metadata": {},
   "source": [
    "Functions to measure time for n iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd7f78dd-74cb-44de-9bdc-57be2247c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%02dm %02ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    return asMinutes(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1a744e-5f0e-46d1-97eb-c0391c1604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_words(output):\n",
    "    words=[]\n",
    "    for vec in output:\n",
    "        top_val, top_i = vec.data.topk(1)\n",
    "        if top_i.item() == end_index: \n",
    "            break\n",
    "        words.append(rus_vec.index2word[top_i.item()])\n",
    "    return words\n",
    "\n",
    "def target_to_words(target):\n",
    "    words=[]\n",
    "    for i in target:\n",
    "        words.append(rus_vec.index2word[i.item()])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd49a54-d3c4-436f-81af-051535c2d875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2119e42-b1a8-4137-a429-fb481ee9b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(output,target):\n",
    "    weights = [1,1,1,1]\n",
    "    if len(output) == 0: \n",
    "        return 0\n",
    "    if len(output)<4:\n",
    "        for i in range(4-len(output)):\n",
    "            weights[-i-1]=0\n",
    "    res = sentence_bleu([output], target, weights=tuple(weights))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53983b-87d1-4c01-a5fa-8c781c6ba46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b40e4d-339a-4a58-aa91-74f0b5675afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea22921-e0db-4d97-a155-d0c0aaccb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_t, target_t, encoder, decoder, enc_opt, dec_opt, loss_func, max_l=MAX_L):\n",
    "    \n",
    "    input_l = input_t.size(0)\n",
    "    target_l = target_t.size(0)\n",
    "    loss = 0\n",
    "    acc = 0 \n",
    "    \n",
    "    enc_opt.zero_grad()\n",
    "    dec_opt.zero_grad()\n",
    "    enc_hidden = encoder.initial_hidden\n",
    "    enc_outs = torch.zeros(max_l, encoder.hidden_size, device=device)\n",
    "        \n",
    "    for i in range(input_l):\n",
    "        enc_out, enc_hidden = encoder(input_t[i], enc_hidden)\n",
    "        enc_outs[i] = enc_out[0, 0]\n",
    "    dec_in = torch.tensor([[start_index]],device=device) #we pass start as initial input\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_outs = []\n",
    "    \n",
    "    for i in range(target_l):\n",
    "        dec_out, dec_hidden, dec_attention = decoder(dec_in, dec_hidden, enc_outs)\n",
    "        loss += loss_func(dec_out,target_t[i])\n",
    "        acc += accuracy(dec_out, target_t[i])\n",
    "        dec_in = target_t[i] #teacher forcing\n",
    "        dec_outs.append(dec_out)\n",
    "       \n",
    "    \n",
    "    target_w = target_to_words(target_t)\n",
    "    output_w = output_to_words(dec_outs)\n",
    "\n",
    "    bleu_acc = bleu(output_w, target_w)    \n",
    "      \n",
    "    loss.backward()\n",
    "    enc_opt.step()\n",
    "    dec_opt.step()\n",
    "    \n",
    "    return loss.item()/target_l, bleu_acc, acc/target_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6dc97f6-2406-49e0-be07-30eacffaca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterations(encoder, decoder, n, print_every=10000, plot_every=100, lr=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    print_bleu_total=0\n",
    "    print_acc_total = 0\n",
    "    \n",
    "    enc_opt = optim.SGD(encoder.parameters(), lr=lr)\n",
    "    dec_opt = optim.SGD(decoder.parameters(), lr=lr)\n",
    "    training_pairs = [prepare_tensors(train_set.sample(1)) for i in range(n)]\n",
    "    loss_func = nn.NLLLoss()\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        training_pair = training_pairs[i-1]\n",
    "        input_t = training_pair[0]\n",
    "        target_t = training_pair[1]\n",
    "        \n",
    "        loss, bleu_acc, acc = train(input_t, target_t, encoder, decoder, enc_opt, dec_opt, loss_func)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        print_bleu_total += bleu_acc\n",
    "        print_acc_total += acc\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total/print_every\n",
    "            print_loss_total = 0\n",
    "            print_bleu = print_bleu_total / print_every\n",
    "            print_bleu_total=0\n",
    "            print_acc =  print_acc_total / print_every\n",
    "            print_acc_total=0\n",
    "            print('time:{} iteration: {} {:.1f}% loss: {:.4f} bleu acc: {:.4f} acc: {:.4f}'.format(timeSince(start), i, i / n * 100, print_loss_avg, print_bleu, print_acc))\n",
    "            \n",
    "        if i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eab5af3-27df-4fe2-b7c3-75c221d9137f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:04m 58s iteration: 10000 10.0% loss: 5.2574 bleu acc: 0.0010 acc: 0.3074\n",
      "time:08m 44s iteration: 20000 20.0% loss: 4.1653 bleu acc: 0.0031 acc: 0.4101\n",
      "time:12m 33s iteration: 30000 30.0% loss: 3.5668 bleu acc: 0.0061 acc: 0.4630\n",
      "time:16m 20s iteration: 40000 40.0% loss: 3.1268 bleu acc: 0.0115 acc: 0.5047\n",
      "time:20m 06s iteration: 50000 50.0% loss: 2.7935 bleu acc: 0.0168 acc: 0.5374\n",
      "time:23m 55s iteration: 60000 60.0% loss: 2.4945 bleu acc: 0.0239 acc: 0.5666\n",
      "time:27m 56s iteration: 70000 70.0% loss: 2.2975 bleu acc: 0.0316 acc: 0.5885\n",
      "time:31m 44s iteration: 80000 80.0% loss: 2.1018 bleu acc: 0.0370 acc: 0.6107\n",
      "time:35m 27s iteration: 90000 90.0% loss: 2.0349 bleu acc: 0.0395 acc: 0.6134\n",
      "time:39m 09s iteration: 100000 100.0% loss: 1.9610 bleu acc: 0.0401 acc: 0.6153\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "N=100000\n",
    "encoder = EncoderRNN(eng_vec.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, rus_vec.n_words).to(device)\n",
    "\n",
    "plot_losses = iterations(encoder, decoder, N, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a142dafd-2e1b-49ae-9d55-b05bbb20b5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23cdf2c2280>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(0,N,100),plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2312d4b-f970-4501-aed9-f1c5b4cfa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_l=MAX_L):\n",
    "    with torch.no_grad():\n",
    "        input_t = torch.tensor(eng_vec.vectorize_line(sentence), dtype=torch.long, device=device).view(-1, 1)\n",
    "        input_l = input_t.size()[0]\n",
    "        enc_hidden = encoder.initial_hidden\n",
    "        enc_outs = torch.zeros(max_l, encoder.hidden_size, device=device)\n",
    "        for i in range(input_l):\n",
    "            enc_out, enc_hidden = encoder(input_t[i], enc_hidden)\n",
    "            enc_outs[i]=enc_out[0,0]\n",
    "        \n",
    "        dec_in = torch.tensor([[start_index]], device=device)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_words=[]\n",
    "        for i in range(max_l):\n",
    "            dec_out, dec_hidden, dec_attention = decoder(dec_in, dec_hidden, enc_outs)\n",
    "            top_v, top_i = dec_out.data.topk(1)\n",
    "            if top_i.item() == 0: \n",
    "                dec_words.append(end_token)\n",
    "                break\n",
    "            else:\n",
    "                dec_words.append(rus_vec.index2word[top_i.item()])\n",
    "            dec_in = top_i.squeeze().detach()\n",
    "        \n",
    "        return dec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2e8483-7545-4a05-8109-f70eadbd0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    pairs = train_set.sample(n)\n",
    "    for rus,eng in zip(pairs.rus,pairs.eng):\n",
    "        print('Input: ', eng)\n",
    "        print('Target: ', rus)\n",
    "        output_w = evaluate(encoder, decoder, eng)\n",
    "        output_sentence = ' '.join(output_w)\n",
    "        print('Output: ', output_sentence)\n",
    "        del output_w[-1]\n",
    "        target_w = rus.split(' ')\n",
    "        print('Bleu: ', bleu(output_w, target_w))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1829878-a200-4826-8d61-8a07cbe1a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  we must respect toms decision\n",
      "Target:  мы должны уважать решение тома\n",
      "Output:  мы должны уважать тома E_\n",
      "Bleu:  2.96676514467623e-309\n",
      "\n",
      "Input:  i found a strange object lying on the road\n",
      "Target:  я нашёл странный предмет лежащий на дороге\n",
      "Output:  я забыл на своего отца E_\n",
      "Bleu:  0.0\n",
      "\n",
      "Input:  the child burst out crying\n",
      "Target:  ребёнок расплакался\n",
      "Output:  в шесть E_\n",
      "Bleu:  0\n",
      "\n",
      "Input:  i have two sons one is in boston and the other is in chicago\n",
      "Target:  у меня два сына один в бостоне другой в чикаго\n",
      "Output:  у меня в бостоне и одна в бостоне и одна же E_\n",
      "Bleu:  0.0\n",
      "\n",
      "Input:  i bought a book about animals\n",
      "Target:  я купила книгу про животных\n",
      "Output:  я прочёл книгу про E_\n",
      "Bleu:  0.0\n",
      "\n",
      "Input:  they wont come back\n",
      "Target:  они не вернутся\n",
      "Output:  они не так E_\n",
      "Bleu:  7.41691286169047e-309\n",
      "\n",
      "Input:  we want to go to australia\n",
      "Target:  мы хотим поехать в австралию\n",
      "Output:  мы хотим поехать в австралию E_\n",
      "Bleu:  1.0\n",
      "\n",
      "Input:  you were supposed to be there\n",
      "Target:  предполагалось что вы там\n",
      "Output:  ты там туда так ли E_\n",
      "Bleu:  0.0\n",
      "\n",
      "Input:  are you still considering doing that\n",
      "Target:  вы всё ещё намереваетесь сделать это\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mente\\anaconda3\\envs\\torch_learning\\lib\\site-packages\\nltk\\translate\\bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  ты рассказал в бостоне говорил E_\n",
      "Bleu:  0\n",
      "\n",
      "Input:  turn around\n",
      "Target:  обернись\n",
      "Output:  у неё E_\n",
      "Bleu:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed1c07-02d5-439b-af3d-d3b8291d7159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
