{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267612ea",
   "metadata": {},
   "source": [
    "# Skin segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb29e7b",
   "metadata": {},
   "source": [
    "In this assignement you will train classifier to assign colors to skin or no skin classes. The data is taken from [Skin Segmentation Data Set](http://archive.ics.uci.edu/ml/datasets/Skin+Segmentation#) in the UCI Machine Learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b63e7",
   "metadata": {},
   "source": [
    "The  data is in a plain text format and contains four columns. First three contain RGB color data  represented as integers in the range 0-255, and the last column is an integer label  with 1 representing skin and 2 representing no skin. This file we can load directly into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d63e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509d588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/Skin_NonSkin.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dffe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 74.  85. 123.]\n",
      " [ 73.  84. 122.]\n",
      " [ 72.  83. 121.]\n",
      " ...\n",
      " [163. 162. 112.]\n",
      " [163. 162. 112.]\n",
      " [255. 255. 255.]]\n",
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "rgb  = data[:,:3].astype('float32')\n",
    "lbl = data[:,3].astype('float32') \n",
    "lbl = 2-lbl\n",
    "\n",
    "print(rgb)\n",
    "print(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f988fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245057"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3f08ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194198,  50859], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(lbl.astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe6159",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99ade4",
   "metadata": {},
   "source": [
    "Train the neural network to distinguish skin from no skin colors. Calculate the accuracy on train and validation sets. Calculate true positives rate and false positives rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376daae3-1962-4893-b065-6684d7865af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x=torch.from_numpy(rgb)\n",
    "tensor_y=torch.from_numpy(lbl)\n",
    "\n",
    "train_size=round(0.8*len(data))\n",
    "test_size=len(data)-train_size\n",
    "\n",
    "dataset=torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
    "train, test = torch.utils.data.random_split(dataset, (train_size, test_size))\n",
    "\n",
    "train_set = torch.utils.data.DataLoader(train,batch_size=64)\n",
    "test_set = torch.utils.data.DataLoader(test,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c079c7-8d5f-4ba9-a62e-180437c8cacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_no: 0\tloss : 0.5954208970069885\t accuracy : 75.0\n",
      "data_batch_no: 500\tloss : 0.14904335141181946\t accuracy : 98.4375\n",
      "data_batch_no: 1000\tloss : 0.13780145347118378\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.12516091763973236\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.10362161695957184\t accuracy : 98.4375\n",
      "data_batch_no: 2500\tloss : 0.1172817200422287\t accuracy : 96.875\n",
      "data_batch_no: 3000\tloss : 0.0448819100856781\t accuracy : 100.0\n",
      "epoch: 0\tloss : 0.12019004672765732\t accuracy : 96.70671844482422\n",
      "data_batch_no: 0\tloss : 0.06643105298280716\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.045141711831092834\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07790052890777588\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.10192867368459702\t accuracy : 96.875\n",
      "data_batch_no: 2000\tloss : 0.05744212120771408\t accuracy : 98.4375\n",
      "data_batch_no: 2500\tloss : 0.07643819600343704\t accuracy : 96.875\n",
      "data_batch_no: 3000\tloss : 0.024105247110128403\t accuracy : 100.0\n",
      "epoch: 1\tloss : 0.05839230865240097\t accuracy : 98.72664642333984\n",
      "data_batch_no: 0\tloss : 0.035292886197566986\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.02781035751104355\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07203236222267151\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06290838867425919\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.035840000957250595\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.057042501866817474\t accuracy : 98.4375\n",
      "data_batch_no: 3000\tloss : 0.01724930852651596\t accuracy : 100.0\n",
      "epoch: 2\tloss : 0.047688473016023636\t accuracy : 98.74092102050781\n",
      "data_batch_no: 0\tloss : 0.02407677099108696\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.023147951811552048\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07250364124774933\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.13962404429912567\t accuracy : 95.3125\n",
      "data_batch_no: 2000\tloss : 0.03124365396797657\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.04520859569311142\t accuracy : 98.4375\n",
      "data_batch_no: 3000\tloss : 0.013925842940807343\t accuracy : 100.0\n",
      "epoch: 3\tloss : 0.0452456921339035\t accuracy : 98.81588745117188\n",
      "data_batch_no: 0\tloss : 0.018656611442565918\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.01835334300994873\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07187140733003616\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.10189515352249146\t accuracy : 96.875\n",
      "data_batch_no: 2000\tloss : 0.025729114189743996\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.03611292690038681\t accuracy : 98.4375\n",
      "data_batch_no: 3000\tloss : 0.012090186588466167\t accuracy : 100.0\n",
      "epoch: 4\tloss : 0.04269280657172203\t accuracy : 98.7970199584961\n",
      "data_batch_no: 0\tloss : 0.01610725186765194\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.015541493892669678\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07326478511095047\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.07363949716091156\t accuracy : 96.875\n",
      "data_batch_no: 2000\tloss : 0.020279262214899063\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.02895534411072731\t accuracy : 98.4375\n",
      "data_batch_no: 3000\tloss : 0.010984700173139572\t accuracy : 100.0\n",
      "epoch: 5\tloss : 0.042536891996860504\t accuracy : 98.82965850830078\n",
      "data_batch_no: 0\tloss : 0.014609098434448242\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.015011158771812916\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07410424947738647\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.24165654182434082\t accuracy : 92.1875\n",
      "data_batch_no: 2000\tloss : 0.015410313382744789\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.02517271228134632\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.010293452069163322\t accuracy : 100.0\n",
      "epoch: 6\tloss : 0.04271199554204941\t accuracy : 98.8745346069336\n",
      "data_batch_no: 0\tloss : 0.013697533868253231\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.014662694185972214\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.0917837843298912\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.05971403047442436\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.01304566115140915\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.02115635946393013\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.009276529774069786\t accuracy : 100.0\n",
      "epoch: 7\tloss : 0.035472702234983444\t accuracy : 99.14276885986328\n",
      "data_batch_no: 0\tloss : 0.012346543371677399\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.016716662794351578\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.0633961483836174\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.0598471462726593\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.011817391030490398\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.018320750445127487\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.008478165604174137\t accuracy : 100.0\n",
      "epoch: 8\tloss : 0.033954787999391556\t accuracy : 99.16724395751953\n",
      "data_batch_no: 0\tloss : 0.0113074267283082\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.01817702129483223\t accuracy : 98.4375\n",
      "data_batch_no: 1000\tloss : 0.058668479323387146\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06023315712809563\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.010775052942335606\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.015937354415655136\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.00791529007256031\t accuracy : 100.0\n",
      "epoch: 9\tloss : 0.034081365913152695\t accuracy : 99.1871337890625\n",
      "data_batch_no: 0\tloss : 0.010561522096395493\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.01395073439925909\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.057982563972473145\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06047431379556656\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.06963266432285309\t accuracy : 98.4375\n",
      "data_batch_no: 2500\tloss : 0.014290571212768555\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.007582151331007481\t accuracy : 100.0\n",
      "epoch: 10\tloss : 0.035737235099077225\t accuracy : 99.15653228759766\n",
      "data_batch_no: 0\tloss : 0.011701511219143867\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.014509507454931736\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.05872178450226784\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.060714177787303925\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.009689297527074814\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.012676483020186424\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.007123234681785107\t accuracy : 100.0\n",
      "epoch: 11\tloss : 0.033058762550354004\t accuracy : 99.24424743652344\n",
      "data_batch_no: 0\tloss : 0.009499000385403633\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.01682490110397339\t accuracy : 98.4375\n",
      "data_batch_no: 1000\tloss : 0.11675328016281128\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.061038631945848465\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.009263062849640846\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.012835068628191948\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.006848219782114029\t accuracy : 100.0\n",
      "epoch: 12\tloss : 0.03343817591667175\t accuracy : 99.19376373291016\n",
      "data_batch_no: 0\tloss : 0.009131502360105515\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.014951568096876144\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.07709053158760071\t accuracy : 96.875\n",
      "data_batch_no: 1500\tloss : 0.061153389513492584\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.00900544784963131\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.011021641083061695\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.006676001474261284\t accuracy : 100.0\n",
      "epoch: 13\tloss : 0.03283165767788887\t accuracy : 99.14531707763672\n",
      "data_batch_no: 0\tloss : 0.00891318079084158\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.006069154012948275\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.05906360223889351\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06139542534947395\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.008683178573846817\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.010337756015360355\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.006507932208478451\t accuracy : 100.0\n",
      "epoch: 14\tloss : 0.032968103885650635\t accuracy : 99.23149871826172\n",
      "data_batch_no: 0\tloss : 0.008649753406643867\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.025795001536607742\t accuracy : 98.4375\n",
      "data_batch_no: 1000\tloss : 0.05673705413937569\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06153959035873413\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.008487425744533539\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.009881595149636269\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.0062926579266786575\t accuracy : 100.0\n",
      "epoch: 15\tloss : 0.03644059598445892\t accuracy : 99.23506927490234\n",
      "data_batch_no: 0\tloss : 0.008396544493734837\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.007020683027803898\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.058874186128377914\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06172268092632294\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.008241703733801842\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.00996079295873642\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.0061469655483961105\t accuracy : 100.0\n",
      "epoch: 16\tloss : 0.03191107138991356\t accuracy : 99.21875\n",
      "data_batch_no: 0\tloss : 0.008205900900065899\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.018172308802604675\t accuracy : 98.4375\n",
      "data_batch_no: 1000\tloss : 0.05808905139565468\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.0618593730032444\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.00811210460960865\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.00924765970557928\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.0060644252225756645\t accuracy : 100.0\n",
      "epoch: 17\tloss : 0.03453577309846878\t accuracy : 99.18865966796875\n",
      "data_batch_no: 0\tloss : 0.008077388629317284\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.009853601455688477\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.05890612676739693\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.0619962178170681\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.007946882396936417\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.00911244098097086\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.005946224555373192\t accuracy : 100.0\n",
      "epoch: 18\tloss : 0.0321350172162056\t accuracy : 99.22028350830078\n",
      "data_batch_no: 0\tloss : 0.007949372753500938\t accuracy : 100.0\n",
      "data_batch_no: 500\tloss : 0.005834215320646763\t accuracy : 100.0\n",
      "data_batch_no: 1000\tloss : 0.057721611112356186\t accuracy : 98.4375\n",
      "data_batch_no: 1500\tloss : 0.06210058927536011\t accuracy : 98.4375\n",
      "data_batch_no: 2000\tloss : 0.007947583682835102\t accuracy : 100.0\n",
      "data_batch_no: 2500\tloss : 0.008876895532011986\t accuracy : 100.0\n",
      "data_batch_no: 3000\tloss : 0.005887215957045555\t accuracy : 100.0\n",
      "epoch: 19\tloss : 0.03657358139753342\t accuracy : 99.1866226196289\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,6)\n",
    "        self.fc2 = nn.Linear(6,2)\n",
    "        self.fc3 = nn.Linear(2,1)  \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 20\n",
    "\n",
    "model = Net(input_shape=tensor_x.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    for j,(x,y) in enumerate(train_set):\n",
    "    \n",
    "        output = model(x)\n",
    " \n",
    "        loss = loss_func(output,y.reshape(-1,1))\n",
    "        epoch_loss+=loss\n",
    "        acc = 100 * torch.sum(output.round()==y.reshape(-1,1))/len(x) \n",
    "        epoch_acc+=acc\n",
    "        \n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(j%500)==0:\n",
    "            print(\"data_batch_no: {}\\tloss : {}\\t accuracy : {}\".format(j,loss,acc))\n",
    "    epoch_loss=epoch_loss/len(train_set)\n",
    "    epoch_acc=epoch_acc/len(train_set)\n",
    "    print(\"epoch: {}\\tloss : {}\\t accuracy : {}\".format(i,epoch_loss,epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b23bc7-aad5-4da6-8c9f-bde7353a3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 99.33502197265625 fpr : 0.006599469110369682 tpr : 0.9931507110595703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_accuracies=[]\n",
    "fp=0\n",
    "tp=0\n",
    "positives=0\n",
    "negatives=0\n",
    "with torch.no_grad():\n",
    "    for j, (x,y) in enumerate(test_set):\n",
    "        output=model(x)\n",
    "        predicted=output.round()\n",
    "        negatives += torch.sum(y.reshape(-1,1)==0)\n",
    "        positives += torch.sum(y.reshape(-1,1)==1)\n",
    "        fp += torch.sum(torch.logical_and(predicted.round()!=y.reshape(-1,1), predicted.round() == 1))\n",
    "        tp += torch.sum(torch.logical_and(predicted.round()==y.reshape(-1,1), predicted.round() == 1))\n",
    "        acc = 100 * torch.sum(predicted==y.reshape(-1,1))/len(x) \n",
    "        test_accuracies.append(acc)\n",
    "\n",
    "test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "fpr = fp/negatives\n",
    "tpr = tp/positives\n",
    "print(\"test accuracy: {} fpr : {} tpr : {}\".format(test_accuracy,fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8d64a-8b24-42d3-a059-3c5565b3f020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
